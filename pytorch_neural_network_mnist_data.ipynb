{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">using cuda: NVIDIA GeForce RTX <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3080</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "using cuda: NVIDIA GeForce RTX \u001b[1;36m3080\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "# if yes, set default tensor type to cuda\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cuda'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, inodes, hnodes, onodes, learning_rate):\n",
    "        # call the base class's initialisation too\n",
    "        super().__init__()\n",
    "        \n",
    "        # dimensions\n",
    "        self.inodes, self.hnodes, self.onodes = inodes, hnodes, onodes\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        # define the layers and their sizes, turn off bias\n",
    "        self.linear_ih = nn.Linear(inodes, hnodes, bias=False)\n",
    "        self.linear_ho = nn.Linear(hnodes, onodes, bias=False)\n",
    "        \n",
    "        # define activation function\n",
    "        self.activation = nn.Sigmoid()\n",
    "        # define inverse activation function\n",
    "        self.inverse_activation_function = torch.logit\n",
    "        \n",
    "        # create error function\n",
    "        # self.error_function = torch.nn.MSELoss(size_average=False)  # size_average is deprecated\n",
    "        self.error_function = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "        # create optimiser, using simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.SGD(self.parameters(), self.lr)\n",
    "\n",
    "        # use GPU if it is available\n",
    "        self.ftensor = torch.cuda.FloatTensor if device.type=='cuda' else torch.FloatTensor\n",
    "            \n",
    "    \n",
    "    def forward(self, inputs_list):\n",
    "        # convert list to a 2-D FloatTensor then wrap in Variable \n",
    "        inputs = Variable(self.ftensor(inputs_list).view(1, self.inodes))\n",
    "            \n",
    "        # combine input layer signals into hidden layer\n",
    "        hidden_inputs = self.linear_ih(inputs)\n",
    "        # apply sigmiod activation function\n",
    "        hidden_outputs = self.activation(hidden_inputs)\n",
    "        \n",
    "        # combine hidden layer signals into output layer\n",
    "        final_inputs = self.linear_ho(hidden_outputs)\n",
    "        # apply sigmiod activation function\n",
    "        final_outputs = self.activation(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # calculate the output of the network\n",
    "        output = self.forward(inputs_list)\n",
    "\n",
    "        # create a Variable out of the target vector, doesn't need gradients calculated\n",
    "        target_variable = Variable(self.ftensor(targets_list).view(1, self.onodes), requires_grad=False)\n",
    "        \n",
    "        # calculate error\n",
    "        loss = self.error_function(output, target_variable)\n",
    "        # print(loss.data[0])\n",
    "\n",
    "        # zero gradients, perform a backward pass, and update the weights.\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "        \n",
    "        \n",
    "    def backquery(self, targets_list):\n",
    "        \"\"\"backquery the neural network.\"\"\"\n",
    "        def _scale(signal):\n",
    "            # scale signal to 0.01 to 0.99\n",
    "            signal -= signal.min().item()\n",
    "            signal /= signal.max().item()\n",
    "            signal *= 0.98\n",
    "            signal += 0.01\n",
    "            return signal\n",
    "        \n",
    "        # create a Variable out of the target vector, doesn't need gradients calculated\n",
    "        target_variable = Variable(self.ftensor(targets_list).view(1, self.onodes), requires_grad=False).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(target_variable)\n",
    "        # calculate the signal out of the hidden layer and scale them back to 0.01 to 0.99\n",
    "        hidden_outputs = _scale(torch.matmul(self.linear_ho.weight.T, final_inputs))\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        # calculate the signal out of the input layer and scale them back to 0.01 to .99\n",
    "        inputs = _scale(torch.matmul(self.linear_ih.weight.T, hidden_inputs))\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes, hidden_nodes, output_nodes = 784, 200, 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = Classifier(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# move neural network to the GPU\n",
    "if device.type == 'cuda':\n",
    "    n.cuda()\n",
    "    \n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10  # best\n",
    "# epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "with open(\"./mnist_dataset/mnist_train.csv\", 'r') as training_data_file:\n",
    "    training_data_list = training_data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32min 38s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 -c\n",
    "\n",
    "# train the neural network\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        \n",
    "        # create rotated variations\n",
    "        # rotated anticlockwise by x degrees\n",
    "        x = 10\n",
    "        inputs_plusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28, 28), x, cval=0.01, order=1, reshape=False)\n",
    "        n.train(inputs_plusx_img.reshape(784), targets)\n",
    "        # rotated clockwise by x degrees\n",
    "        inputs_minusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28, 28), -x, cval=0.01, order=1, reshape=False)\n",
    "        n.train(inputs_minusx_img.reshape(784), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the mnist test data CSV file into a list\n",
    "with open(\"./mnist_dataset/mnist_test.csv\", 'r') as test_data_file:\n",
    "    test_data_list = test_data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.forward(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    m, label = outputs.max(1)\n",
    "    # print(m, label)\n",
    "    # append correct or incorrect to list\n",
    "    # need to extract from pytorch tensor via np to compare to python integer\n",
    "    # if (np.asarray(label)[0] == correct_label):\n",
    "    if (label.item() == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">performance = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9823</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "performance = \u001b[1;36m0.9823\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(f\"performance = {scorecard_array.sum()/scorecard_array.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test backquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">matplotlib.image.AxesImage</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f46499e0070</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mmatplotlib.image.AxesImage\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f46499e0070\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Figure</span><span style=\"color: #000000; text-decoration-color: #000000\"> size 432x288 with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\"> Axes</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 432x288 with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 9\n",
    "targets = np.zeros(output_nodes) + 0.01\n",
    "targets[label] = 0.99\n",
    "\n",
    "image_data = n.backquery(targets).cpu().detach().numpy().reshape(28, 28)\n",
    "plt.imshow(image_data, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Classifier</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>linear_ih<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>linear_ho<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>activation<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span>error_function<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MSELoss</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mClassifier\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear_ih\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m784\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m200\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear_ho\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m200\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0merror_function\u001b[1m)\u001b[0m: \u001b[1;35mMSELoss\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.epochs = 10\n",
    "n.performance = 0.9823\n",
    "n.trainging_time = \"32 min 38 s\"\n",
    "\n",
    "with open(f'./trained_classifiers/pytorch_tensor_classifiler_{epochs}.pkl', 'wb') as f:\n",
    "    pickle.dump(n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">matplotlib.image.AxesImage</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f464971bc70</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mmatplotlib.image.AxesImage\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f464971bc70\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Figure</span><span style=\"color: #000000; text-decoration-color: #000000\"> size 432x288 with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\"> Axes</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 432x288 with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pickled object\n",
    "with open(f'./trained_classifiers/pytorch_tensor_classifiler_{epochs}.pkl', 'rb') as f:\n",
    "    new_n = pickle.load(f)\n",
    "    \n",
    "image_data = new_n.backquery(targets).cpu().detach().numpy().reshape(28, 28)\n",
    "plt.imshow(image_data, cmap='Greys', interpolation='None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
